{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file IO\n",
    "import matplotlib.pyplot as plt # Plotting Figures\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Tarihe göre ayırdım, buna gerek yok\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "from pandas import Series, DataFrame\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "import matplotlib as mpl\n",
    "\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "############ 1 -> EXPLANATORY DATA ANALYSIS (Introduction) ############\n",
    "\n",
    "# Imports CSV file into Pandas Data Frame\n",
    "df = pd.read_csv('migros.csv')\n",
    "df = df[df.Volume > 0]\n",
    "df = df[df.index > 1500]\n",
    "\n",
    "dolarf = pd.read_csv('dolar.csv')\n",
    "\n",
    "del df['Open']\n",
    "del df['High']\n",
    "del df['Low']\n",
    "df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d', errors='coerce')\n",
    "df.Volume = df.Volume.astype(int)\n",
    "\n",
    "# Indicators:\n",
    "\n",
    "# Moving Average\n",
    "df['MA10'] = df.Close.rolling(window=10).mean().shift(-5)\n",
    "\n",
    "# Exponential Moving Average\n",
    "df['EMA'] = df.Close.ewm(span=10, min_periods=5,adjust=True).mean().shift(-5) # Dünün EMA'sı\n",
    "\n",
    "# Rate of Change: 10 günlük değişim yüzdesi\n",
    "df['ROC'] = df.Close.pct_change(10).shift(-10)\n",
    "\n",
    "# Volatility\n",
    "df['Volatility'] = df.Close.rolling(window=10).std().shift(-10)\n",
    "\n",
    "# Classification as Up(1)/Down(0)\n",
    "threshold = -0.01\n",
    "df['Change'] = df.Close.diff()\n",
    "df['Up/Down'] = np.where(df.Change > threshold, 1,0)\n",
    "\n",
    "# Dolar\n",
    "df['Dolar'] = dolarf['Dollar-TRY']\n",
    "\n",
    "df.head() # Shows first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(500)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.grid(True)\n",
    "df19 = df[df.Date > \"2019-01-01\"]\n",
    "plt.plot(df19['Date'], df19['Close'],label='Close')\n",
    "plt.plot(df19['Date'], df19['MA10'], label='MA 10 Days')\n",
    "plt.plot(df19['Date'], df19['EMA'], label='Exponential MA 10 Days')\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row ve column sayısı\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints out column names using columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs some general information about the dataframe\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows basic statistical characteristics of each numerical feature (int64 and float64 types): number of non-missing values,\n",
    "# mean, standard deviation, range, median, 0.25 and 0.75 quartiles.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows how the Volume is distributed\n",
    "print(df['Volume'].describe())\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.distplot(df['Volume'], color='g', bins=300, hist_kws={'alpha': 0.4});"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows how the Close is distributed\n",
    "print(df['Close'].describe())\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.distplot(df['Close'], color='g', bins=300, hist_kws={'alpha': 0.4});"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical data distribution\n",
    "list(set(df.dtypes.tolist()))\n",
    "df_num = df.select_dtypes(include = ['float64', 'int64'])\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid having the matplotlib verbose informations\n",
    "df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll try to find which features are strongly correlated with Close.\n",
    "# We'll store them in a var called precious_features_list. \n",
    "df_num_corr = df_num.corr()['Close'][:-1] # -1 because the latest row is SalePrice\n",
    "precious_features_list = df_num_corr[abs(df_num_corr) > 0.5].sort_values(ascending=False)\n",
    "print(\"There is {} strongly correlated values with Close:\\n{}\".format(len(precious_features_list), precious_features_list))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot precious features correlated with Close Attribute\n",
    "for i in range(0, len(df_num.columns), 5):\n",
    "    sns.pairplot(data=df_num,\n",
    "                x_vars=df_num.columns[i:i+5],\n",
    "                y_vars=['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature relationship\n",
    "# Trying to plot all the numerical features in a seaborn pairplot\n",
    "# will take us too much time and will be hard to interpret.\n",
    "# We can try to see if some variables are linked between each other\n",
    "# and then explain their relation with common sense.\n",
    "\n",
    "corr = df_num.corr() # We already examined SalePrice correlations\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n",
    "            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
    "            annot=True, annot_kws={\"size\": 8}, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows how Close is related to the Volume feature. \n",
    "# We'll do this using a crosstab contingency table and also through visual analysis with Seaborn\n",
    "#pd.crosstab(df['Close'], df['Volume'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots a correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, vmin=-1, vmax=1, center=0, \n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(), rotation=45, horizontalalignment='right'\n",
    ");\n",
    "\n",
    "# Blue means positive, red means negative\n",
    "# The stronger the color, the larger the correlation magnitude"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use pandas_profiling for more detailed report\n",
    "# pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram for all the columns of the dataframe. This shows the frequency of values in all the columns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "df.hist(sharex = False, sharey = False, xlabelsize = 12, ylabelsize = 12, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting index as date\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d')\n",
    "#df.index = df['Date']\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(24,12))\n",
    "plt.plot(df['Date'], df['Close'], label='Close Price history')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df[(df.index > 20) & (df.index < 3842)] # NaN row'lar çöpe\n",
    "testset = df[df.index > 3841] # Test set'i 4 Kasım ve sonrası"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.fillna(method='ffill')\n",
    "\n",
    "X_linear_train = dataset[['MA10', 'EMA', 'ROC', 'Volatility']].values\n",
    "y_linear_train = dataset['Close'].values\n",
    "\n",
    "X_linear_test = testset[['MA10', 'EMA', 'ROC', 'Volatility']].values\n",
    "y_linear_test = testset['Close'].values\n",
    "\n",
    "# Next, we split 80% of the data to the training set while 20% of the data to test set using below code.\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 3841 \t2019-11-04\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "sns.distplot(dataset['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets train our model.\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_linear_train, y_linear_train)\n",
    "\n",
    "y_linear_pred = regressor.predict(X_linear_test)\n",
    "\n",
    "predictions = pd.DataFrame({'Actual': y_linear_test, 'Predicted': y_linear_pred, 'Diff': y_linear_test - y_linear_pred})\n",
    "\n",
    "df1 = predictions\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot(kind='bar',figsize=(10,8))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_linear_test, y_linear_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_linear_test, y_linear_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_linear_test, y_linear_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_linear_test, color = 'red', label = 'Real Price')\n",
    "plt.plot(y_linear_pred, color = 'green', label = 'Predicted Price')\n",
    "plt.title('MIGROS Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MIGROS Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_logistic_train = dataset[['MA10', 'EMA', 'ROC', 'Volatility']].values\n",
    "y_logistic_train = dataset['Up/Down'].values\n",
    "\n",
    "X_logistic_test = testset[['MA10', 'EMA', 'ROC', 'Volatility']].values\n",
    "y_logistic_test = testset['Up/Down'].values\n",
    "\n",
    "regressor = LogisticRegression(solver='lbfgs')\n",
    "regressor.fit(X_logistic_train, y_logistic_train)\n",
    "\n",
    "y_logistic_pred = regressor.predict(X_logistic_test)\n",
    "\n",
    "log_predictions = pd.DataFrame({'Actual': y_logistic_test, 'Predicted': y_logistic_pred})\n",
    "\n",
    "df2 = log_predictions\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_logistic_test, y_logistic_pred)\n",
    "\n",
    "# TruePositive FN\n",
    "# FalseP TNegative\n",
    "# Şeklinde array verecek\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(2000, 1, 1)\n",
    "end = datetime.datetime(2019, 1, 30)\n",
    "\n",
    "df = web.DataReader(\"MGROS.IS\", 'yahoo', start, end)\n",
    "df.tail()\n",
    "\n",
    "# Imports CSV file into Pandas Data Frame\n",
    "# df = pd.read_csv('migros.csv')\n",
    "# df.head() # Shows first 5 rows of the dataframe\n",
    "\n",
    "close_px = df['Close']\n",
    "mavg = close_px.rolling(window=100).mean()\n",
    "\n",
    "# Adjusting the size of matplotlib\n",
    "mpl.rc('figure', figsize=(8, 7))\n",
    "mpl.__version__\n",
    "\n",
    "# Adjusting the style of matplotlib\n",
    "style.use('ggplot')\n",
    "\n",
    "close_px.plot(label='MIGROS')\n",
    "mavg.plot(label='mavg')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = close_px / close_px.shift(1) - 1\n",
    "rets.plot(label='return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competitors\n",
    "dfcomp = web.DataReader(['BIZIM.IS', 'CRFSA.IS', 'BIMAS.IS', 'SOKM.IS', 'MGROS.IS'],'yahoo',start=start,end=end)['Close']\n",
    "dfcomp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retscomp = dfcomp.pct_change()\n",
    "corr = retscomp.corr()\n",
    "\n",
    "plt.matshow(corr.corr())\n",
    "plt.xticks(range(len(corr.columns)), corr.columns)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(corr, cmap='hot', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr)), corr.columns)\n",
    "plt.yticks(range(len(corr)), corr.columns);\n",
    "\n",
    "retscomp = dfcomp.pct_change()\n",
    "corr = retscomp.corr()\n",
    "print(corr)\n",
    "print(retscomp.columns)\n",
    "\n",
    "plt.scatter(retscomp['MGROS.IS'], retscomp['BIMAS.IS'])\n",
    "plt.xlabel('Returns MGROS')\n",
    "plt.ylabel('Returns BIMAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(retscomp, diagonal='kde', figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(retscomp.mean(), retscomp.std())\n",
    "plt.xlabel('Expected returns')\n",
    "plt.ylabel('Risk')\n",
    "for label, x, y in zip(retscomp.columns, retscomp.mean(), retscomp.std()):\n",
    "    plt.annotate(\n",
    "        label, \n",
    "        xy = (x, y), xytext = (20, -20),\n",
    "        textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
    "        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "\n",
    "dfreg = df.loc[:,['Close','Volume']]\n",
    "dfreg['HL_PCT'] = (df['High'] - df['Low']) / df['Close'] * 100.0\n",
    "dfreg['PCT_change'] = (df['Close'] - df['Open']) / df['Open'] * 100.0\n",
    "\n",
    "dfreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing value\n",
    "dfreg.fillna(value=-99999, inplace=True)\n",
    "# We want to separate 1 percent of the data to forecast\n",
    "forecast_out = int(math.ceil(0.01 * len(dfreg)))\n",
    "# Separating the label here, we want to predict the Close\n",
    "forecast_col = 'Close'\n",
    "dfreg['label'] = dfreg[forecast_col].shift(-forecast_out)\n",
    "X = np.array(dfreg.drop(['label'], 1))\n",
    "# Scale the X so that everyone can have the same distribution for linear regression\n",
    "X = sklearn.preprocessing.scale(X)\n",
    "# Finally We want to find Data Series of late X and early X (train) for model generation and evaluation\n",
    "X_lately = X[-forecast_out:]\n",
    "X = X[:-forecast_out]\n",
    "# Separate label and identify it as y\n",
    "y = np.array(dfreg['label'])\n",
    "y = y[:-forecast_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Generation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(dfreg.head())\n",
    "\n",
    "# Linear regression\n",
    "clfreg = LinearRegression(n_jobs=-1)\n",
    "clfreg.fit(X, y)\n",
    "\n",
    "# Quadratic Regression 2\n",
    "clfpoly2 = make_pipeline(PolynomialFeatures(2), Ridge())\n",
    "clfpoly2.fit(X, y)\n",
    "\n",
    "# Quadratic Regression 3\n",
    "clfpoly3 = make_pipeline(PolynomialFeatures(3), Ridge())\n",
    "clfpoly3.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfknn = KNeighborsRegressor(n_neighbors=2)\n",
    "clfknn.fit(X_train, y_train)\n",
    "\n",
    "confidencereg = clfreg.score(X_test, y_test)\n",
    "confidencepoly2 = clfpoly2.score(X_test,y_test)\n",
    "confidencepoly3 = clfpoly3.score(X_test,y_test)\n",
    "confidenceknn = clfknn.score(X_test, y_test)\n",
    "print(confidencereg)\n",
    "print(confidencepoly2)\n",
    "print(confidencepoly3)\n",
    "print(confidenceknn)\n",
    "\n",
    "forecast_set = clfknn.predict(X_lately)\n",
    "dfreg['Forecast'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = dfreg.iloc[-1].name\n",
    "last_unix = last_date\n",
    "next_unix = last_unix + datetime.timedelta(days=1)\n",
    "\n",
    "for i in forecast_set:\n",
    "    next_date = next_unix\n",
    "    next_unix += datetime.timedelta(days=1)\n",
    "    dfreg.loc[next_date] = [np.nan for _ in range(len(dfreg.columns)-1)]+[i]\n",
    "dfreg['Close'].tail(500).plot()\n",
    "dfreg['Forecast'].tail(500).plot()\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(testy, ns_probs)\n",
    "lr_auc = roc_auc_score(testy, lr_probs)\n",
    "\n",
    "X = X.reshape(X.shape[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}